{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f081bd40-9d0f-41d4-a2b2-c0612af9a9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "import string\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "import time\n",
    "import scipy\n",
    "from scipy.spatial import distance\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae03c4ec-5fdd-42d8-aea0-01d89a811d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = set(stopwords.words('english'))\n",
    "PUNCT_TRANS = str.maketrans('', '', string.punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbb898c-f5cc-483f-9698-f5f907880e0b",
   "metadata": {},
   "source": [
    "# Functions\n",
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c426c76c-7410-422b-9570-446ea15030f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path='./liar_dataset'):\n",
    "    features = ['ID', 'label', 'statement', 'subject', 'speaker', 'job', 'state', 'affiliation',\n",
    "         'barely-true', 'false', 'half-true', 'mostly-true', 'pant-on-fire', 'context']\n",
    "    \n",
    "    # merge train.tsv + valid.tsv\n",
    "    TRAIN = pd.concat([pd.read_csv(path+'/train.tsv', delimiter='\\t', names=features, quoting=3),\n",
    "                        pd.read_csv(path+'/valid.tsv', delimiter='\\t', names=features, quoting=3)],\n",
    "                        ignore_index=True)\n",
    "\n",
    "    TEST = pd.read_csv(path+'/test.tsv', delimiter='\\t', names=features, quoting=3)\n",
    "    \n",
    "    return TRAIN, TEST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3069a82-94c8-463c-9eba-516e424f207e",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f693dcd-6ccd-412e-bb6b-ab8150c75eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtract_current_credit(row):\n",
    "    \"\"\"\n",
    "    \n",
    "    Subtract the current label from the credit history of current statement.\n",
    "        \n",
    "    \"\"\"\n",
    "    label = row['label'] \n",
    "    try:\n",
    "        row[label] -= 1  \n",
    "    except:\n",
    "        pass\n",
    "    return row\n",
    "    \n",
    "def fill_na(data):\n",
    "    \"\"\"\n",
    "\n",
    "    Preproces steps of LIAR dataset which is include:\n",
    "        * Define which are text features\n",
    "        * Define which are numeric features (credit history)\n",
    "        * Fill the blanks (missing cell) of text features with word [unknow]\n",
    "        * Prevent data leakage from numeric features\n",
    "            According to dataset author: \n",
    "                \"Credit history include the count of the current statement, \n",
    "                it is important to subtract the current label from the credit history when using this \n",
    "                meta data vector in prediction experiments.\"\n",
    "\n",
    "    \"\"\"\n",
    "    text_features = ['statement', 'subject', 'speaker', 'job', 'state', 'affiliation', 'context']\n",
    "    num_features = ['barely-true', 'false', 'half-true', 'mostly-true', 'pant-on-fire']\n",
    "    data[text_features] = data[text_features].fillna(\"unknown\").astype(str)\n",
    "    data[num_features] = data[num_features].fillna(0).astype(int)\n",
    "    \n",
    "    # subtract current_credit\n",
    "    data = data.apply(subtract_current_credit, axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0d0b3a0-69dc-4efc-a67a-cf8cb98b5f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TXT_preprocess(text):\n",
    "    \"\"\"\n",
    "    \n",
    "    Clean statement feature.\n",
    "    \n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    text = text.translate(PUNCT_TRANS)\n",
    "    text = ' '.join([word for word in word_tokenize(text) if word not in STOPWORDS])\n",
    "    return text\n",
    "\n",
    "def context_preprocess(text):\n",
    "    \"\"\"\n",
    "    \n",
    "    Clean context feature.\n",
    "    \n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub('e mail|e-mail|email|mailer','mail', text)\n",
    "    text = re.sub('television','tv', text)\n",
    "    text = re.sub('website','web', text)\n",
    "    text = text.translate(PUNCT_TRANS)\n",
    "    text = ' '.join([word for word in word_tokenize(text) if word not in STOPWORDS])\n",
    "    return text\n",
    "    \n",
    "def subject_preprocess(text):\n",
    "    \"\"\"\n",
    "    \n",
    "    Clean subject feature.\n",
    "    \n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    text = ' '.join(text.split(','))\n",
    "    return text\n",
    "\n",
    "def job_preprocess(text):\n",
    "    \"\"\"\n",
    "    \n",
    "    Clean job feature.\n",
    "    \n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    text = text.translate(PUNCT_TRANS)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a88451d-7bcd-46a2-88ad-45958e67a2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TXT_Transformer(TransformerMixin, BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X['statement'].apply(TXT_preprocess)\n",
    "\n",
    "class CT_Transformer(TransformerMixin, BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        output = pd.DataFrame()\n",
    "        output['context'] = X['context'].apply(context_preprocess)\n",
    "        output['subject'] = X['subject'].apply(subject_preprocess)\n",
    "        output['job'] = X['job'].apply(job_preprocess)\n",
    "        output['state'] = X['state'].str.lower()\n",
    "        output['affiliation'] = X['affiliation'].str.lower()\n",
    "        return output\n",
    "        \n",
    "class CT_Vectorizer(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self):\n",
    "        self.context_vtr = TfidfVectorizer()\n",
    "        self.subject_vtr = CountVectorizer(binary=True)\n",
    "        self.job_vtr = CountVectorizer(binary=True)\n",
    "        self.state_vtr = CountVectorizer(binary=True)\n",
    "        self.affiliation_vtr = CountVectorizer(binary=True)\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        self.context_vtr.fit(X['context'])\n",
    "        self.subject_vtr.fit(X['subject'])\n",
    "        self.job_vtr.fit(X['job'])\n",
    "        self.state_vtr.fit(X['state'])\n",
    "        self.affiliation_vtr.fit(X['affiliation'])\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return scipy.sparse.hstack((\n",
    "            self.context_vtr.transform(X['context']),\n",
    "            self.subject_vtr.transform(X['subject']),\n",
    "            self.job_vtr.transform(X['job']),\n",
    "            self.state_vtr.transform(X['state']),\n",
    "            self.affiliation_vtr.transform(X['affiliation'])\n",
    "        ))\n",
    "        \n",
    "class CH_Transformer(TransformerMixin, BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[['barely-true', 'false', 'half-true', 'mostly-true', 'pant-on-fire']].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bf4d8d-1f99-4727-9833-6702ef9e6daa",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "238af477-3fcc-4112-aaff-b704055d890a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Binary_models(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, *, param_grid=None):\n",
    "        self.models = []\n",
    "        self.param_grid = param_grid\n",
    "        self.maps = [\n",
    "                {\n",
    "                    'pants-fire'  : 0, \n",
    "                    'false'       : 0, \n",
    "                    'barely-true' : 1, \n",
    "                    'half-true'   : 1, \n",
    "                    'mostly-true' : 1, \n",
    "                    'true'        : 1\n",
    "                },\n",
    "                {\n",
    "                    'pants-fire'  : 0, \n",
    "                    'false'       : 0, \n",
    "                    'barely-true' : 1, \n",
    "                    'half-true'   : 1, \n",
    "                    'mostly-true' : 0, \n",
    "                    'true'        : 0\n",
    "                },\n",
    "                {\n",
    "                    'pants-fire'  : 0, \n",
    "                    'false'       : 0, \n",
    "                    'barely-true' : 0, \n",
    "                    'half-true'   : 0, \n",
    "                    'mostly-true' : 1, \n",
    "                    'true'        : 1\n",
    "                },\n",
    "                {\n",
    "                    'pants-fire'  : 0, \n",
    "                    'false'       : 0, \n",
    "                    'barely-true' : 0, \n",
    "                    'half-true'   : 1, \n",
    "                    'mostly-true' : 1, \n",
    "                    'true'        : 1\n",
    "                }\n",
    "            ]\n",
    "    def fit(self, X, y=None):\n",
    "        for i in range(4):\n",
    "            y_ = np.vectorize(self.maps[i].get)(y)\n",
    "            search = GridSearchCV(\n",
    "                estimator=XGBClassifier(),\n",
    "                param_grid=self.param_grid,\n",
    "                scoring= 'neg_log_loss',\n",
    "                cv=3\n",
    "            )\n",
    "            search.fit(X, y_)\n",
    "            self.models.append(search)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        pred = np.empty((X.shape[0], 4))\n",
    "        for i in range(4):\n",
    "            pred[:, i] = self.models[i].predict_proba(X)[:, 0]\n",
    "        return pred\n",
    "\n",
    "class MultiClass_model(ClassifierMixin, BaseEstimator):\n",
    "    \n",
    "    def __init__(self, *, param_grid=None):\n",
    "        self.model = None\n",
    "        self.param_grid = param_grid\n",
    "        self.map = {\n",
    "            'pants-fire'  : 0, \n",
    "            'false'       : 1, \n",
    "            'barely-true' : 2, \n",
    "            'half-true'   : 3, \n",
    "            'mostly-true' : 4, \n",
    "            'true'        : 5\n",
    "        }\n",
    "        self.truth_class = {\n",
    "            0 : 'pants-fire', \n",
    "            1 : 'false'     ,\n",
    "            2 : 'barely-true',\n",
    "            3 : 'half-true'  ,\n",
    "            4 : 'mostly-true',\n",
    "            5 : 'true'\n",
    "        }\n",
    "    def fit(self, X, y=None):\n",
    "        y_ = np.vectorize(self.map.get)(y)\n",
    "        search = GridSearchCV(\n",
    "            estimator=XGBClassifier(),\n",
    "            param_grid=self.param_grid,\n",
    "            scoring= 'neg_log_loss',\n",
    "            cv=5\n",
    "        )\n",
    "        self.model = search.fit(X, y_)\n",
    "        return self\n",
    "        \n",
    "    def predict(self, X):\n",
    "        pred = self.model.predict(X)\n",
    "        return np.vectorize(self.truth_class.get)(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0898724-38f1-463d-98a4-1d264d13a3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN, TEST = read_data()\n",
    "\n",
    "y_train = TRAIN['label'].values\n",
    "y_test = TEST['label'].values\n",
    "\n",
    "X_train = fill_na(TRAIN).drop(columns=['ID', 'label', 'speaker'])\n",
    "X_test = fill_na(TEST).drop(columns=['ID', 'label', 'speaker'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff9995f0-3b63-49e2-a590-2306cda12cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_param_grid = {\n",
    "        'n_estimators': [50, 100],\n",
    "        'learning_rate': [.1, .2, .3, .4, .5],\n",
    "        'max_depth': [2, 3, 4]\n",
    "    }\n",
    "multi_param_grid = {\n",
    "    'objective' : ['multi:softmax'],\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'learning_rate': [.01, .1, .5],\n",
    "    'max_depth': [3, 6, 9]\n",
    "}\n",
    "k_params = [500, 200, 100, 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f0c9b6d-c954-42f2-b118-9bb7088a4010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=500\n",
      "TRAINING accuracy: 68.74%\n",
      "TEST accuracy: 46.53%\n",
      " --------------------\n",
      "K=200\n",
      "TRAINING accuracy: 67.70%\n",
      "TEST accuracy: 48.01%\n",
      " --------------------\n",
      "K=100\n",
      "TRAINING accuracy: 66.67%\n",
      "TEST accuracy: 49.49%\n",
      " --------------------\n",
      "K=50\n",
      "TRAINING accuracy: 88.85%\n",
      "TEST accuracy: 54.79%\n",
      " --------------------\n"
     ]
    }
   ],
   "source": [
    "for k in k_params:\n",
    "    TXT_pipeline = Pipeline([\n",
    "            ('TXT_clean', TXT_Transformer()),\n",
    "            ('TXT_vector', TfidfVectorizer()),\n",
    "            ('TXT_chi2', SelectKBest(score_func=chi2)),\n",
    "            ('TXT_binary', Binary_models(param_grid=bin_param_grid))\n",
    "        ])\n",
    "    CT_pipeline = Pipeline([\n",
    "            ('CT_clean', CT_Transformer()),\n",
    "            ('CT_vector', CT_Vectorizer()),\n",
    "            ('CT_binary', Binary_models(param_grid=bin_param_grid))\n",
    "        ])\n",
    "    CH_pipeline = Pipeline([('CH_clean', CH_Transformer())])\n",
    "    \n",
    "    model_pipeline = Pipeline(\n",
    "        [\n",
    "            ('Merge', FeatureUnion(\n",
    "                [\n",
    "                    ('TXT', TXT_pipeline),\n",
    "                    ('CT', CT_pipeline),\n",
    "                    ('CH', CH_pipeline)\n",
    "                ]\n",
    "                ,n_jobs=-1\n",
    "            )),\n",
    "            ('Scaler', MinMaxScaler()),\n",
    "            ('Classifier', MultiClass_model(param_grid=multi_param_grid))\n",
    "        ])\n",
    "    model_pipeline.set_params(Merge__TXT__TXT_chi2__k= k)\n",
    "    model_pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    pred_train = model_pipeline.predict(X_train)\n",
    "    pred_test = model_pipeline.predict(X_test)\n",
    "    \n",
    "    score_train = accuracy_score(y_train, pred_train)\n",
    "    score_test = accuracy_score(y_test, pred_test)\n",
    "    print(f'K={k}')\n",
    "    print(f'TRAINING accuracy: {score_train*100:.2f}%')\n",
    "    print(f'TEST accuracy: {score_test*100:.2f}%\\n','-'*20)\n",
    "    joblib.dump(model_pipeline, f'models/M_chi2_{k}.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
